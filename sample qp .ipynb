{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8920ac0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting language-tool-python\n",
      "  Downloading language_tool_python-2.7.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\anees\\anaconda3\\lib\\site-packages (from language-tool-python) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anees\\anaconda3\\lib\\site-packages (from language-tool-python) (4.64.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\anees\\anaconda3\\lib\\site-packages (from requests->language-tool-python) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anees\\anaconda3\\lib\\site-packages (from requests->language-tool-python) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\anees\\anaconda3\\lib\\site-packages (from requests->language-tool-python) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anees\\anaconda3\\lib\\site-packages (from requests->language-tool-python) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\anees\\anaconda3\\lib\\site-packages (from tqdm->language-tool-python) (0.4.6)\n",
      "Downloading language_tool_python-2.7.3-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: language-tool-python\n",
      "Successfully installed language-tool-python-2.7.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install language-tool-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba76b20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original sentence is:\n",
      "He have one sister.\n",
      "After correction:\n",
      "He has one sister.\n"
     ]
    }
   ],
   "source": [
    "from language_tool_python import LanguageTool\n",
    "\n",
    "def correct_sentence(sentence):\n",
    "    # Create a LanguageTool instance\n",
    "    tool = LanguageTool('en-US')\n",
    "\n",
    "    # Get matches for the given sentence\n",
    "    matches = tool.check(sentence)\n",
    "\n",
    "    # If there are no matches, the sentence is correct\n",
    "    if len(matches) == 0:\n",
    "        print(\"The sentence is grammatically correct.\")\n",
    "        return sentence\n",
    "\n",
    "    # If there are matches, correct the sentence\n",
    "    corrected_sentence = tool.correct(sentence)\n",
    "\n",
    "    print(\"The original sentence is:\")\n",
    "    print(sentence)\n",
    "    print(\"After correction:\")\n",
    "    print(corrected_sentence)\n",
    "\n",
    "    return corrected_sentence\n",
    "\n",
    "# Example sentence\n",
    "sentence = \"He have one sister.\"\n",
    "\n",
    "# Check and correct the sentence\n",
    "corrected = correct_sentence(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51e8074e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original sentence is:\n",
      "He don't likes the movie.\n",
      "After changing negatives to positives:\n",
      "He does like the movie.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def identify_and_replace_negatives(sentence):\n",
    "    # Create a LanguageTool instance\n",
    "    tool = LanguageTool('en-US')\n",
    "\n",
    "    # Get matches for the given sentence\n",
    "    matches = tool.check(sentence)\n",
    "\n",
    "    # If there are no matches, the sentence is correct\n",
    "    if len(matches) == 0:\n",
    "        print(\"The sentence is grammatically correct.\")\n",
    "        return sentence\n",
    "\n",
    "    # If there are matches, correct the sentence\n",
    "    corrected_sentence = tool.correct(sentence)\n",
    "\n",
    "    # Split the sentence into tokens\n",
    "    tokens = corrected_sentence.split()\n",
    "\n",
    "    # List of negative words and their positive counterparts\n",
    "    negative_words = {\n",
    "        \"don't\": \"do\",\n",
    "        \"doesn't\": \"does\",\n",
    "        \"isn't\": \"is\",\n",
    "        \"aren't\": \"are\",\n",
    "        \"wasn't\": \"was\",\n",
    "        \"weren't\": \"were\",\n",
    "        \"can't\": \"can\",\n",
    "        \"couldn't\": \"could\",\n",
    "        \"won't\": \"will\",\n",
    "        \"wouldn't\": \"would\",\n",
    "        \"shouldn't\": \"should\",\n",
    "        \"mightn't\": \"might\",\n",
    "        \"mustn't\": \"must\",\n",
    "        \"shalln't\": \"shall\",\n",
    "        \"needn't\": \"need\",\n",
    "        \"oughtn't\": \"ought\",\n",
    "        \"hasn't\": \"has\",\n",
    "        \"haven't\": \"have\",\n",
    "        \"hadn't\": \"had\",\n",
    "        \"did't\": \"did\"\n",
    "    }\n",
    "\n",
    "    # Replace negative tokens with their positive counterparts\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token.lower() in negative_words:\n",
    "            tokens[i] = negative_words[token.lower()]\n",
    "\n",
    "    # Join the tokens back into a sentence\n",
    "    positive_sentence = \" \".join(tokens)\n",
    "\n",
    "    print(\"The original sentence is:\")\n",
    "    print(sentence)\n",
    "    print(\"After changing negatives to positives:\")\n",
    "    print(positive_sentence)\n",
    "\n",
    "    return positive_sentence\n",
    "\n",
    "# Example sentence\n",
    "sentence = \"He don't likes the movie.\"\n",
    "\n",
    "# Check and replace negative tokens with positive ones\n",
    "positive_sentence = identify_and_replace_negatives(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f44ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90401125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most informative phrase: nlp\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def find_most_informative_phrase(sentences):\n",
    "    # Create the TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Calculate TF-IDF scores for the sentences\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "\n",
    "    # Get feature names (words)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Calculate the average TF-IDF score for each word across all sentences\n",
    "    avg_tfidf_scores = np.mean(tfidf_matrix, axis=0)\n",
    "\n",
    "    # Get the index of the word with the highest average TF-IDF score\n",
    "    most_informative_index = np.argmax(avg_tfidf_scores)\n",
    "\n",
    "    # Get the most informative word\n",
    "    most_informative_word = feature_names[most_informative_index]\n",
    "\n",
    "    return most_informative_word\n",
    "\n",
    "# Example list of sentences\n",
    "sentences = [\n",
    "    \"Natural language processing (NLP) is a field of artificial intelligence.\",\n",
    "    \"It deals with the interaction between computers and humans using natural language.\",\n",
    "    \"NLP techniques are used to analyze, understand, and generate human language.\",\n",
    "    \"Sentiment analysis is one application of NLP.\",\n",
    "    \"It aims to determine the sentiment or emotion expressed in a piece of text.\"\n",
    "]\n",
    "\n",
    "# Find the most informative phrase in the paragraph\n",
    "most_informative_phrase = find_most_informative_phrase(sentences)\n",
    "\n",
    "print(\"Most informative phrase:\", most_informative_phrase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de35b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most informative phrase (bigram): natural language\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def find_most_informative_phrase(sentences):\n",
    "    # Create the TF-IDF vectorizer with n-gram range (2, 2) for bigrams\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(2, 2))\n",
    "\n",
    "    # Calculate TF-IDF scores for the sentences\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "\n",
    "    # Get feature names (bigrams)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Calculate the average TF-IDF score for each bigram across all sentences\n",
    "    avg_tfidf_scores = np.mean(tfidf_matrix, axis=0)\n",
    "\n",
    "    # Get the index of the bigram with the highest average TF-IDF score\n",
    "    most_informative_index = np.argmax(avg_tfidf_scores)\n",
    "\n",
    "    # Get the most informative bigram\n",
    "    most_informative_bigram = feature_names[most_informative_index]\n",
    "\n",
    "    return most_informative_bigram\n",
    "\n",
    "# Example list of sentences\n",
    "sentences = [\n",
    "    \"Natural language processing (NLP) is a field of artificial intelligence.\",\n",
    "    \"It deals with the interaction between computers and humans using natural language.\",\n",
    "    \"NLP techniques are used to analyze, understand, and generate human language.\",\n",
    "    \"Sentiment analysis is one application of NLP.\",\n",
    "    \"It aims to determine the sentiment or emotion expressed in a piece of text.\"\n",
    "]\n",
    "\n",
    "# Find the most informative phrase (bigram) in the paragraph\n",
    "most_informative_phrase = find_most_informative_phrase(sentences)\n",
    "\n",
    "print(\"Most informative phrase (bigram):\", most_informative_phrase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98e271b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most informative sentence: It aims to determine the sentiment or emotion expressed in a piece of text.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def find_most_informative_sentence(sentences):\n",
    "    # Create the TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Calculate TF-IDF scores for the sentences\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "\n",
    "    # Calculate the average TF-IDF score for each sentence\n",
    "    avg_tfidf_scores = np.mean(tfidf_matrix, axis=1)\n",
    "\n",
    "    # Get the index of the sentence with the highest average TF-IDF score\n",
    "    most_informative_index = np.argmax(avg_tfidf_scores)\n",
    "\n",
    "    # Get the most informative sentence\n",
    "    most_informative_sentence = sentences[most_informative_index]\n",
    "\n",
    "    return most_informative_sentence\n",
    "\n",
    "# Example list of sentences (paragraph)\n",
    "sentences = [\n",
    "    \"Natural language processing (NLP) is a field of artificial intelligence.\",\n",
    "    \"It deals with the interaction between computers and humans using natural language.\",\n",
    "    \"NLP techniques are used to analyze, understand, and generate human language.\",\n",
    "    \"Sentiment analysis is one application of NLP.\",\n",
    "    \"It aims to determine the sentiment or emotion expressed in a piece of text.\"\n",
    "]\n",
    "\n",
    "# Find the most informative sentence in the paragraph\n",
    "most_informative_sentence = find_most_informative_sentence(sentences)\n",
    "\n",
    "print(\"Most informative sentence:\", most_informative_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19075f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
